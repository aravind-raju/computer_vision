{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a331e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53175e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "var = 5\n",
    "sigma = var ** 0.5\n",
    "gaussian = np.random.normal(mean, sigma, (28, 28))\n",
    "fonts_folder = \"D:/projects/computer_vision/sudoku_solver/fonts/\"\n",
    "batch_sz = 500\n",
    "n_iters = 2500\n",
    "features_train = 100000\n",
    "#num_epochs = int(n_iters / (features_train / batch_sz))\n",
    "num_epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "transform = transforms.Compose([transforms.Resize((28, 28)), transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, ), (0.5, ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66097b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise():\n",
    "    mean = random.randint(0, 2)\n",
    "    var = random.randint(0, 11)\n",
    "    sigma = var ** 0.5\n",
    "    gaussian = np.random.normal(mean, sigma, (28, 28))\n",
    "    return gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8791b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintedMNIST(Dataset):\n",
    "    \"\"\"Generates images containing a single digit from font\"\"\"\n",
    "\n",
    "    def __init__(self, N, random_state, transform=None):\n",
    "        \"\"\"\"\"\"\n",
    "        self.N = N\n",
    "        self.random_state = random_state\n",
    "        self.transform = transform\n",
    "\n",
    "        #fonts_folder = \"fonts\"\n",
    "\n",
    "        self.fonts = [fonts_folder + \"helvetica_bold1.ttf\", fonts_folder + 'AovelSansRounded-rdDL.ttf', fonts_folder + 'Paul-le1V.ttf']\n",
    "        #self.fonts = glob.glob(fonts_folder + \"/*.ttf\")\n",
    "\n",
    "        random.seed(random_state)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        target = random.randint(0, 9)\n",
    "        color = 0\n",
    "        # Generate image\n",
    "        img = Image.new(\"L\", (256, 256))\n",
    "        img = np.array(img)\n",
    "        img[img == 0] = 225\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        size = 200\n",
    "        x = 20\n",
    "        y = 20\n",
    "\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(random.choice(self.fonts), size)\n",
    "        draw.text((x, y), str(target), color, font=font)\n",
    "        shape = [(0, 0), (256 - 10, 256 - 10)]\n",
    "        draw.rectangle(shape, outline =\"black\", width=4)\n",
    "\n",
    "        img = img.resize((28, 28), Image.BILINEAR)\n",
    "        #gaussian = get_noise()\n",
    "        noisy_image = img + gaussian\n",
    "        noisy_image = Image.fromarray(noisy_image)\n",
    "        if self.transform:\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "            #img = self.transform(img)\n",
    "\n",
    "        return noisy_image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5050e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=0)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "        x = self.cnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        out = self.softmax(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        y_hat_pred = self.flatten(y_hat.argmax(axis=1)).float().requires_grad_(True)\n",
    "        correct = (y == y_hat_pred).sum()\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs, 'correct': correct, 'total': len(y)}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        y_hat_pred = self.flatten(y_hat.argmax(axis=1)).float().requires_grad_(True)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        correct = (y == y_hat_pred).sum()\n",
    "        logs = {'val_loss': loss}\n",
    "        return {'loss': loss, 'log': logs, 'correct': correct, 'total': len(y)}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        correct = sum([x[\"correct\"] for  x in outputs])\n",
    "        total = sum([x[\"total\"] for  x in outputs])\n",
    "        self.log(\"train_loss\", avg_loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", correct/total, prog_bar=True, logger=True)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        correct = sum([x[\"correct\"] for  x in outputs])\n",
    "        total = sum([x[\"total\"] for  x in outputs])\n",
    "        self.log(\"val_loss\", avg_loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", correct/total, prog_bar=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_set = PrintedMNIST(100000, -666, transform)\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_sz, shuffle=False, num_workers=0, drop_last=True)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_set = PrintedMNIST(5000, 33, transform)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_sz, num_workers=0)\n",
    "        return val_loader\n",
    "\n",
    "    def flatten(self, t):\n",
    "        t = t.reshape(1, -1)\n",
    "        t = t.squeeze()\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc256eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "tb_logger = loggers.TensorBoardLogger('logs/')\n",
    "model = CNNModel()\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, checkpoint_callback=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546191bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type      | Params\n",
      "---------------------------------------\n",
      "0 | cnn1     | Conv2d    | 832   \n",
      "1 | maxpool1 | MaxPool2d | 0     \n",
      "2 | cnn2     | Conv2d    | 51.3 K\n",
      "3 | maxpool2 | MaxPool2d | 0     \n",
      "4 | fc1      | Linear    | 10.2 K\n",
      "5 | softmax  | Softmax   | 0     \n",
      "---------------------------------------\n",
      "62.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.3 K    Total params\n",
      "0.249     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|                                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\miniconda\\envs\\opencv\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:106: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "D:\\Application\\miniconda\\envs\\opencv\\lib\\site-packages\\torchvision\\transforms\\functional.py:75: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n",
      "D:\\Application\\miniconda\\envs\\opencv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\miniconda\\envs\\opencv\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|▋                                                                                                                                            | 1/210 [00:01<02:06,  1.65it/s, loss=2.34, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\miniconda\\envs\\opencv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:398: LightningDeprecationWarning: One of the returned values {'correct', 'total', 'log'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  f\"One of the returned values {set(extra.keys())} has a `grad_fn`. We will detach it automatically\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 200/210 [02:08<00:06,  1.56it/s, loss=2.37, v_num=27]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 202/210 [02:09<00:05,  1.57it/s, loss=2.37, v_num=27]\u001b[A\n",
      "Validating:  20%|████████████████████████████████                                                                                                                                | 2/10 [00:01<00:05,  1.59it/s]\u001b[A\n",
      "Validating:  30%|████████████████████████████████████████████████                                                                                                                | 3/10 [00:01<00:04,  1.61it/s]\u001b[A\n",
      "Epoch 0:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 205/210 [02:11<00:03,  1.57it/s, loss=2.37, v_num=27]\u001b[A\n",
      "Validating:  50%|████████████████████████████████████████████████████████████████████████████████                                                                                | 5/10 [00:03<00:03,  1.60it/s]\u001b[A\n",
      "Validating:  60%|████████████████████████████████████████████████████████████████████████████████████████████████                                                                | 6/10 [00:03<00:02,  1.60it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 208/210 [02:12<00:01,  1.57it/s, loss=2.37, v_num=27]\u001b[A\n",
      "Validating:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 8/10 [00:04<00:01,  1.62it/s]\u001b[A\n",
      "Validating:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 9/10 [00:05<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 210/210 [02:14<00:00,  1.57it/s, loss=2.37, v_num=27, val_loss=2.360, val_acc=0.104]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████████████████████████████████████████████████████▊   | 201/210 [02:07<00:05,  1.59it/s, loss=2.36, v_num=27, val_loss=2.360, val_acc=0.104, train_loss=2.370, train_acc=0.090]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  10%|████████████████                                                                                                                                                | 1/10 [00:00<00:06,  1.48it/s]\u001b[A\n",
      "Validating:  20%|████████████████████████████████                                                                                                                                | 2/10 [00:01<00:05,  1.55it/s]\u001b[A\n",
      "Epoch 1:  97%|██████████████████████████████████████████████████████████████████████▉  | 204/210 [02:09<00:03,  1.59it/s, loss=2.36, v_num=27, val_loss=2.360, val_acc=0.104, train_loss=2.370, train_acc=0.090]\u001b[A\n",
      "Validating:  40%|████████████████████████████████████████████████████████████████                                                                                                | 4/10 [00:02<00:03,  1.56it/s]\u001b[A\n",
      "Validating:  50%|████████████████████████████████████████████████████████████████████████████████                                                                                | 5/10 [00:03<00:03,  1.58it/s]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████████████████████████████████████████████▉ | 207/210 [02:11<00:01,  1.59it/s, loss=2.36, v_num=27, val_loss=2.360, val_acc=0.104, train_loss=2.370, train_acc=0.090]\u001b[A\n",
      "Validating:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 7/10 [00:04<00:01,  1.57it/s]\u001b[A\n",
      "Validating:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 8/10 [00:05<00:01,  1.59it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████| 210/210 [02:13<00:00,  1.59it/s, loss=2.36, v_num=27, val_loss=2.360, val_acc=0.104, train_loss=2.370, train_acc=0.090]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████| 210/210 [02:13<00:00,  1.58it/s, loss=2.36, v_num=27, val_loss=2.360, val_acc=0.0992, train_loss=2.370, train_acc=0.090]\u001b[A\n",
      "Epoch 2:  11%|███████▉                                                                 | 23/210 [00:14<01:55,  1.61it/s, loss=2.36, v_num=27, val_loss=2.360, val_acc=0.0992, train_loss=2.370, train_acc=0.096]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\miniconda\\envs\\opencv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1047: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e3280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ace6b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('D:/projects/computer_vision/sudoku_solver/cell.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img, (28, 28))\n",
    "img = Image.fromarray(img)\n",
    "img = transform(img)\n",
    "img = img.reshape(1, 1, 28, 28)\n",
    "predictions = model(img.float())\n",
    "predictions = predictions.detach().numpy()\n",
    "print(np.argmax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb63171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6831208e-04, 7.4046344e-02, 3.1547007e-01, 1.2510201e-01,\n",
       "        2.6204610e-01, 4.9022799e-03, 4.0500995e-04, 1.8129952e-01,\n",
       "        9.9457242e-03, 2.6514661e-02]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7840990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "img = x[10][0].numpy()\n",
    "img = Image.fromarray(img)\n",
    "img = transform(img)\n",
    "img = img.reshape(1, 1, 28, 28)\n",
    "predictions = model(img.float())\n",
    "predictions = predictions.detach().numpy()\n",
    "print(np.argmax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a90e8754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00c419be",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_image = Image.fromarray(x[10][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9999677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAGUlEQVR4nO3BMQEAAADCoPVPbQdvoAAAeA0JTAAB9ZfCmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x1D3A7B55DD8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_image.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a0fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
